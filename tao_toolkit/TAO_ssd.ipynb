{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzUnDWL26AWD"
      },
      "source": [
        "# TAO SSD\n",
        "\n",
        "TechGo is a project focused on developing an automatic store with object detection models playing a crucial role in identifying user-selected products. A carefully curated dataset consisting of 1397 training samples, 400 validation samples, and 200 testing samples was constructed. The dataset includes six specific labels, namely Coca Cola, Pringles, Doritos, M&M, hands, and person, representing common objects and interactions within a store environment.\n",
        "\n",
        "NOTE: This notebooks is an adaptation of the official one modificated for TechGo project. Official: (https://github.com/NVIDIA-AI-IOT/nvidia-tao/tree/main/tensorflow/ssd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGLBrzF8hKgS"
      },
      "source": [
        "## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n",
        "\n",
        "1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n",
        "2. This increases your time available for the GPU dependent tasks on a Colab instance\n",
        "2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n",
        "3.   Then click on Connect (Top Right)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjpjyNg5c2V9"
      },
      "source": [
        "## Mounting Google drive\n",
        "Mount your Google drive storage to this Colab instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvUVkYw0hzqG",
        "outputId": "6b7da5fc-0fa2-4ee5-d185-6c04546b033f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: GOOGLE_COLAB=1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    %env GOOGLE_COLAB=1\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except:\n",
        "    %env GOOGLE_COLAB=0\n",
        "    print(\"Warning: Not a Colab Environment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bihWWnrqjmA6"
      },
      "source": [
        "# Object Detection using TAO SSD\n",
        "\n",
        "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task.\n",
        "\n",
        "Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
        "\n",
        "<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png\" width=\"1080\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPLxUkkXjmA8"
      },
      "source": [
        "## Learning Objectives\n",
        "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
        "\n",
        "* Take a pretrained resnet18 model and train a ResNet-18 SSD model on the TechGo dataset\n",
        "* Prune the trained SSD model\n",
        "* Retrain the pruned model to recover lost accuracy\n",
        "* Export the pruned model\n",
        "* Run Inference on the trained model\n",
        "* Export the pruned, quantized and retrained model to a .etlt file for deployment to DeepStream\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxwnxWrd7eLw"
      },
      "source": [
        "## 0. Set up env variables and set FIXME parameters <a class=\"anchor\" id=\"head-0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye0UdTi2jmA9"
      },
      "outputs": [],
      "source": [
        "# Setting up env variables for cleaner command line commands.\n",
        "import os\n",
        "\n",
        "%env TAO_DOCKER_DISABLE=1\n",
        "\n",
        "%env KEY=nvidia_tlt\n",
        "#FIXME1\n",
        "%env NUM_GPUS=1\n",
        "#FIXME2\n",
        "%env GPU_INDEX=0\n",
        "\n",
        "#FIXME3 Where you want to save the official repository in your google drive\n",
        "%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/perceptionAI/TechGo/nvidia-tao\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    if not os.path.exists(os.path.join(os.environ[\"COLAB_NOTEBOOKS_PATH\"])):\n",
        "      !git clone https://github.com/NVIDIA-AI-IOT/nvidia-tao.git $COLAB_NOTEBOOKS_PATH\n",
        "else:\n",
        "    if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n",
        "        raise Exception(\"Error, enter the path of the colab notebooks repo correctly\")\n",
        "\n",
        "#FIXME4 set this path to a folder location where pretrained models, checkpoints and log files during different model actions will be saved\n",
        "%env EXPERIMENT_DIR=/content/drive/MyDrive/perceptionAI/TechGo/TAO/results/ssd\n",
        "#FIXME5\n",
        "delete_existing_experiments = False\n",
        "#FIXME6 set this path to a folder location where you want to dataset to be present\n",
        "%env DATA_DIR=/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI/\n",
        "#FIXME7\n",
        "delete_existing_data = False\n",
        "\n",
        "if delete_existing_experiments:\n",
        "    !sudo rm -rf $EXPERIMENT_DIR\n",
        "if delete_existing_data:\n",
        "    !sudo rm -rf $DATA_DIR\n",
        "\n",
        "SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/ssd/specs\"\n",
        "%env SPECS_DIR={SPECS_DIR}\n",
        "# Showing list of specification files.\n",
        "!ls -rlt $SPECS_DIR\n",
        "\n",
        "!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n",
        "!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Css1XfjjmA_"
      },
      "source": [
        "## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW_eepZc8AaX"
      },
      "source": [
        "### 1.1 Transform to KITTI format <a class=\"anchor\" id=\"head-1-1\"></a>\n",
        "By default TAO toolkit works with KITTI or COCO dataset format. In this notebook we will work in transforming yolov7 format to KITTI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aThog0RL8Iov"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dataset anotations for KITTI\n",
        "# https://docs.nvidia.com/tao/tao-toolkit/text/data_annotation_format.html#id4\n",
        "\n",
        "\n",
        "class YOLOtoKITTI:\n",
        "    \"\"\"\n",
        "    The purpose of this class is to Transform YOLOV7 format to KITTI format\n",
        "    \"\"\"\n",
        "    def __init__(self, source: str, destination: str):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the YOLOtoKITTI class.\n",
        "\n",
        "        Args:\n",
        "            source (str): The source directory path containing YOLOV7 format data.\n",
        "            destination (str): The destination directory path for storing the transformed KITTI format data.\n",
        "        \"\"\"\n",
        "        self.source = Path(source)\n",
        "        self.destination = Path(destination)\n",
        "\n",
        "        for split in ['train', 'test', 'valid']:\n",
        "            destination_folder = self.destination / split / 'labels'\n",
        "            destination_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    def __call__(self, width, height, class_names, dataset_name):\n",
        "        \"\"\"\n",
        "        Transforms YOLOV7 format data to KITTI format.\n",
        "\n",
        "        Args:\n",
        "            width (int): The width of the images in pixels.\n",
        "            height (int): The height of the images in pixels.\n",
        "            class_names (dict): a dict of classes\n",
        "            dataset_name (str): The name that I want to use for my transformed dataset\n",
        "        \"\"\"\n",
        "\n",
        "        for folder in self.source.iterdir():\n",
        "            folder = folder / \"labels\"\n",
        "            for fnames in folder.glob('*'):\n",
        "                data=[]\n",
        "                with open(str(fnames), 'r') as fh:\n",
        "\n",
        "                    data=fh.readlines()\n",
        "\n",
        "                for cc, lines in enumerate(data):\n",
        "                    lines=lines.replace('\\n', '').split(\" \")\n",
        "\n",
        "                    n_line = [float(0)] * 15\n",
        "                    n_line[0] = class_names[int(lines[0])]\n",
        "                    # n_line[1] = float(0)\n",
        "                    n_line[2] = int(0)\n",
        "\n",
        "                    x, y, w, h = float(lines[1]), float(lines[2]), float(lines[3]), float(lines[4])\n",
        "                    x, y, w, h = x*width, y*height, w*width, h*height\n",
        "                    x_min, y_min = int(x - w/2), int(y - h/2)\n",
        "                    x_max, y_max = int(x + w/2), int(y + h/2)\n",
        "\n",
        "                    n_line[4], n_line[5], n_line[6], n_line[7] = float(x_min), float(y_min), float(x_max), float(y_max)\n",
        "\n",
        "                    n_line = [float(1) if i > 7 else val for i, val in enumerate(n_line)]\n",
        "\n",
        "                    str1 = ' '.join(str(n_line)).replace(' ', '').replace(',', ' ').replace('[', '').replace(\"]\",\"\").replace(\"'\",\"\").replace('\"',\"\")\n",
        "                    data[cc]= str1 +\"\\n\"\n",
        "\n",
        "                strf = \" \".join(str(x) for x in data)\n",
        "\n",
        "                strf=strf.replace(\"\\n \",\"\\n\")\n",
        "\n",
        "                file = open(str(fnames).replace('Yolov7Format', dataset_name), \"w\")\n",
        "                file.write(strf)\n",
        "                file.close()\n",
        "        print(\"Labels created!\")\n",
        "\n",
        "        # Get images\n",
        "        for source_path in self.source.iterdir():\n",
        "            source_path = source_path / \"images\"\n",
        "            destination_path = str(source_path).replace('Yolov7Format',dataset_name)\n",
        "\n",
        "            if shutil.os.path.exists(destination_path):\n",
        "                shutil.rmtree(destination_path)\n",
        "\n",
        "            shutil.copytree(source_path, destination_path)\n",
        "        print(\"Images created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIQthCZ88Jl7"
      },
      "outputs": [],
      "source": [
        "pipe = YOLOtoKITTI(\n",
        "    source='/content/drive/MyDrive/perceptionAI/TechGo/data/Yolov7Format',\n",
        "    destination='/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb9Pl4Ck8JsD"
      },
      "outputs": [],
      "source": [
        "class_names = {\n",
        "    0: 'coca-cola',\n",
        "    1: 'm&m',\n",
        "    2: 'pringles',\n",
        "    3: 'doritos',\n",
        "    4: 'person',\n",
        "    5: 'hand'\n",
        "}\n",
        "\n",
        "pipe(\n",
        "    width=1920,\n",
        "    height=1080,\n",
        "    class_names=class_names,\n",
        "    dataset_name='TechKITTI'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ1Zhtu6jmBB"
      },
      "source": [
        "### 1.2 Download pre-trained model <a class=\"anchor\" id=\"head-1-1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KD7j8wgjmBB"
      },
      "source": [
        "We will use NGC CLI to get the pre-trained models. For more details, go to [ngc.nvidia.com](ngc.nvidia.com) and click the SETUP on the navigation bar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTJTjZ0RjmBB"
      },
      "outputs": [],
      "source": [
        "# Installing NGC CLI on the local machine.\n",
        "## Download and install\n",
        "%env LOCAL_PROJECT_DIR=/ngc_content/\n",
        "%env CLI=ngccli_cat_linux.zip\n",
        "!sudo mkdir -p $LOCAL_PROJECT_DIR/ngccli && sudo chmod -R 777 $LOCAL_PROJECT_DIR\n",
        "\n",
        "# Remove any previously existing CLI installations\n",
        "!sudo rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n",
        "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n",
        "!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n",
        "!rm $LOCAL_PROJECT_DIR/ngccli/*.zip\n",
        "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n",
        "!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq5ltFbXjmBC"
      },
      "outputs": [],
      "source": [
        "!ngc registry model list nvidia/tao/pretrained_object_detection:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Uugsa5jmBC"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/pretrained_resnet18/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fktXa4j5jmBC"
      },
      "outputs": [],
      "source": [
        "# Pull pretrained model from NGC\n",
        "!ngc registry model download-version nvidia/tao/pretrained_object_detection:resnet10 --dest $EXPERIMENT_DIR/pretrained_resnet10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsMalhpDjmBC"
      },
      "outputs": [],
      "source": [
        "print(\"Check that model is downloaded into dir.\")\n",
        "!ls -l $EXPERIMENT_DIR/pretrained_resnet10/pretrained_object_detection_vresnet10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_26rCobXcri1"
      },
      "source": [
        "## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Cx1_lMded7"
      },
      "source": [
        "### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n",
        "\n",
        "1. Move any data saved to the Colab Instance storage to Google Drive\n",
        "2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n",
        "3.   Then click on Connect (Top Right)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl8BoM0Jhzh9"
      },
      "source": [
        "### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n",
        "Mount your Google drive storage to this Colab instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk2m-N4Nh0Sd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    %env GOOGLE_COLAB=1\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except:\n",
        "    %env GOOGLE_COLAB=0\n",
        "    print(\"Warning: Not a Colab Environment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBV_YWiTc_KM"
      },
      "source": [
        "### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n",
        "Setup the environment necessary to run the TAO Networks by running the bash script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2Xygw-y8fjm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    os.environ[\"bash_script\"] = \"setup_env.sh\"\n",
        "else:\n",
        "    os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n",
        "\n",
        "!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n",
        "\n",
        "!sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2ikae1Kym0r"
      },
      "outputs": [],
      "source": [
        "if os.environ.get(\"PYTHONPATH\",\"\") == \"\":\n",
        "    os.environ[\"PYTHONPATH\"] = \"\"\n",
        "os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n",
        "else:\n",
        "    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf996NR0ym0s"
      },
      "outputs": [],
      "source": [
        "# Reset NVIDIA-DALI version for SSD\n",
        "if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n",
        "    !python3.6 -m pip uninstall nvidia-dali-nvtf-plugin -y\n",
        "    !python3.6 -m pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110==0.31.0\n",
        "    !python3.6 -m pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110==0.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl8fSfXseED3"
      },
      "source": [
        "### 2.4 Reset env variables (Use the same paths which was set in Step 0) <a class=\"anchor\" id=\"head-2-4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_T2vBdzeIcO"
      },
      "outputs": [],
      "source": [
        "# Setting up env variables for cleaner command line commands.\n",
        "import os\n",
        "\n",
        "%env TAO_DOCKER_DISABLE=1\n",
        "\n",
        "%env KEY=nvidia_tlt\n",
        "%env NUM_GPUS=1\n",
        "%env GPU_INDEX=0\n",
        "\n",
        "# Change the paths according to your directory structure, these are just examples\n",
        "%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/perceptionAI/TechGo/nvidia-tao\n",
        "if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n",
        "    raise Exception(\"Error, enter the path of the colab notebooks repo correctly\")\n",
        "%env EXPERIMENT_DIR=/content/drive/MyDrive/perceptionAI/TechGo/TAO/results/ssd\n",
        "%env DATA_DIR=/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI/\n",
        "\n",
        "SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/ssd/specs\"\n",
        "%env SPECS_DIR={SPECS_DIR}\n",
        "# Showing list of specification files.\n",
        "!ls -rlt $SPECS_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brU1qBW6ym0s"
      },
      "source": [
        "## 3. Generate tfrecords <a class=\"anchor\" id=\"head-3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcuJh5xq9DXj"
      },
      "source": [
        "The default SSD data format requires generation of TFRecords.\n",
        "Now we need to modified the proportionated txt files in order to set the tfrecords transformation:\n",
        "- ssd_tfrecords_kitti_train.txt\n",
        "- ssd_tfrecords_kitti_val.txt\n",
        "- ssd_tfrecords_kitti_test.txt (Additional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwJlBB439Dzo"
      },
      "source": [
        "Complete them as follows changing the value of \"train\", \"valid\", \"test\":\n",
        "\n",
        "```\n",
        "kitti_config {\n",
        "  root_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///train\"\n",
        "  image_dir_name: \"images\"\n",
        "  label_dir_name: \"labels\"\n",
        "  image_extension: \".jpg\"\n",
        "  partition_mode: \"random\"\n",
        "  num_partitions: 2\n",
        "  val_split: 0\n",
        "  num_shards: 10\n",
        "}\n",
        "image_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///train\"\n",
        "target_class_mapping {\n",
        "      key: \"m&m\"\n",
        "      value: \"m&m\"\n",
        "  }\n",
        "target_class_mapping {\n",
        "    key: \"doritos\"\n",
        "    value: \"doritos\"\n",
        "}\n",
        "target_class_mapping {\n",
        "    key: \"coca-cola\"\n",
        "    value: \"coca-cola\"\n",
        "}\n",
        "target_class_mapping {\n",
        "    key: \"pringles\"\n",
        "    value: \"pringles\"\n",
        "}\n",
        "target_class_mapping {\n",
        "    key: \"person\"\n",
        "    value: \"person\"\n",
        "}\n",
        "target_class_mapping {\n",
        "    key: \"hand\"\n",
        "    value: \"hand\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFeAnLb3jmBA"
      },
      "outputs": [],
      "source": [
        "# Creating a new directory for the output tfrecords dump.\n",
        "print(\"Converting the training set to TFRecords.\")\n",
        "!mkdir -p $DATA_DIR/tfrecords_ssd/kitti_train && sudo rm -rf $DATA_DIR/tfrecords_ssd/kitti_train/*\n",
        "!tao ssd dataset_convert -d $SPECS_DIR/ssd_tfrecords_kitti_train.txt \\\n",
        "                         -o $DATA_DIR/tfrecords_ssd/kitti_train/ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9rRS57FJD2u"
      },
      "outputs": [],
      "source": [
        "# Creating a new directory for the output tfrecords dump.\n",
        "print(\"Converting the validation set to TFRecords.\")\n",
        "!mkdir -p $DATA_DIR/tfrecords_ssd/kitti_val && sudo rm -rf $DATA_DIR/tfrecords_ssd/kitti_val/*\n",
        "!tao ssd dataset_convert \\\n",
        "         -d $SPECS_DIR/ssd_tfrecords_kitti_val.txt \\\n",
        "         -o $DATA_DIR/tfrecords_ssd/kitti_val/kval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqfdovtDKk8E"
      },
      "outputs": [],
      "source": [
        "# Creating a new directory for the output tfrecords dump.\n",
        "print(\"Converting the testing set to TFRecords.\")\n",
        "!mkdir -p $DATA_DIR/tfrecords_ssd/kitti_test && sudo rm -rf $DATA_DIR/tfrecords_ssd/kitti_test/*\n",
        "!tao ssd dataset_convert \\\n",
        "         -d $SPECS_DIR/ssd_tfrecords_kitti_test.txt \\\n",
        "         -o $DATA_DIR/tfrecords_ssd/kitti_test/ktest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoRSysB8jmBB"
      },
      "outputs": [],
      "source": [
        "!ls -rlt $DATA_DIR/tfrecords/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLR-1tuNjmBC"
      },
      "source": [
        "## 4. Provide training specification <a class=\"anchor\" id=\"head-4\"></a>\n",
        "* Dataset for the train datasets\n",
        "    * In order to use the newly generated dataset, update the dataset_config parameter in the spec file at `$SPECS_DIR/ssd_train_resnet18_kitti.txt`\n",
        "* Augmentation parameters for on the fly data augmentation\n",
        "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n",
        "\n",
        "Important considerations\n",
        "- In this case, the pretrained weights are set in the \"tao ssd train\" command\n",
        "- Remember to set the training size in the aumentation_config section in output_width and output_height. All the training images are going to be resized to that shape.\n",
        "- Remember to add the dataclasses inside dataset_config section\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "random_seed: 42\n",
        "ssd_config {\n",
        "  aspect_ratios_global: \"[1.0, 2.0, 0.5, 3.0, 1.0/3.0]\"\n",
        "  scales: \"[0.05, 0.1, 0.25, 0.4, 0.55, 0.7, 0.85]\"\n",
        "  two_boxes_for_ar1: true\n",
        "  clip_boxes: false\n",
        "  variances: \"[0.1, 0.1, 0.2, 0.2]\"\n",
        "  arch: \"resnet\"\n",
        "  nlayers: 18\n",
        "  freeze_bn: false\n",
        "  freeze_blocks: 0\n",
        "}\n",
        "training_config {\n",
        "  batch_size_per_gpu: 16\n",
        "  num_epochs: 1\n",
        "  enable_qat: false\n",
        "  learning_rate {\n",
        "  soft_start_annealing_schedule {\n",
        "    min_learning_rate: 5e-5\n",
        "    max_learning_rate: 2e-2\n",
        "    soft_start: 0.15\n",
        "    annealing: 0.8\n",
        "    }\n",
        "  }\n",
        "  regularizer {\n",
        "    type: L1\n",
        "    weight: 3e-5\n",
        "  }\n",
        "}\n",
        "eval_config {\n",
        "  validation_period_during_training: 10\n",
        "  average_precision_mode: SAMPLE\n",
        "  batch_size: 16\n",
        "  matching_iou_threshold: 0.5\n",
        "}\n",
        "nms_config {\n",
        "  confidence_threshold: 0.01\n",
        "  clustering_iou_threshold: 0.6\n",
        "  top_k: 200\n",
        "}\n",
        "augmentation_config {\n",
        "    output_width: 300\n",
        "    output_height: 300\n",
        "    output_channel: 3\n",
        "}\n",
        "dataset_config {\n",
        "  data_sources: {\n",
        "    tfrecords_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI/tfrecords_ssd/kitti_train/ktrain*\"\n",
        "    # label_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///train/labels\"\n",
        "    # image_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///train/images\"\n",
        "  }\n",
        "  include_difficult_in_training: true\n",
        "  target_class_mapping {\n",
        "      key: \"m&m\"\n",
        "      value: \"m&m\"\n",
        "  }\n",
        "  target_class_mapping {\n",
        "      key: \"doritos\"\n",
        "      value: \"doritos\"\n",
        "  }\n",
        "  target_class_mapping {\n",
        "      key: \"coca-cola\"\n",
        "      value: \"coca-cola\"\n",
        "  }\n",
        "  target_class_mapping {\n",
        "      key: \"pringles\"\n",
        "      value: \"pringles\"\n",
        "  }\n",
        "  target_class_mapping {\n",
        "      key: \"person\"\n",
        "      value: \"person\"\n",
        "  }\n",
        "  target_class_mapping {\n",
        "      key: \"hand\"\n",
        "      value: \"hand\"\n",
        "  }\n",
        "  validation_data_sources: {\n",
        "      # tfrecords_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI/tfrecords_ssd/kitti_val/kval*\"\n",
        "      label_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///valid/labels\"\n",
        "      image_directory_path: \"/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI///valid/images\"\n",
        "  }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrBlpkKpjmBD"
      },
      "source": [
        "## 5. Run TAO training <a class=\"anchor\" id=\"head-5\"></a>\n",
        "* Provide the sample spec file and the output directory location for models\n",
        "* WARNING: training will take several hours or one day to complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrhPhqlijmBD"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned/1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa3ZQggijmBE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\")\n",
        "!tao ssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n",
        "               -e $SPECS_DIR/300/ssd_train_resnet10_kitti.txt \\\n",
        "               -r $EXPERIMENT_DIR/experiment_dir_unpruned/300 \\\n",
        "               -k $KEY \\\n",
        "               -m $EXPERIMENT_DIR/pretrained_resnet10/pretrained_object_detection_vresnet10/resnet_10.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-IWYxtXjmBE"
      },
      "outputs": [],
      "source": [
        "print('Model for each epoch:')\n",
        "print('---------------------')\n",
        "!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/300/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiieRHDnjmBF"
      },
      "outputs": [],
      "source": [
        "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
        "!cat $EXPERIMENT_DIR/experiment_dir_unpruned/300/ssd_training_log_resnet10.csv\n",
        "%env EPOCH=010"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOpridJOjmBF"
      },
      "source": [
        "## 6. Evaluate trained models <a class=\"anchor\" id=\"head-6\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4GokMw0_KQW"
      },
      "source": [
        "As default, the \"evaluate command\" runs the inference in the validation data source. As a result, it is recommended to create a copy of the training txt file and change the data validation source to our test set and rename it, for example: \"test_set_300.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKgBW8BcjmBF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!tao ssd evaluate --gpu_index=$GPU_INDEX \\\n",
        "                  -e $SPECS_DIR/300/test_set_300.txt \\\n",
        "                  -m $EXPERIMENT_DIR/experiment_dir_unpruned/300/weights/ssd_resnet10_epoch_$EPOCH.tlt \\\n",
        "                  -k $KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n9rR-RTjmBG"
      },
      "source": [
        "## 7. Prune trained models <a class=\"anchor\" id=\"head-7\"></a>\n",
        "* Specify pre-trained model\n",
        "* Equalization criterion (`Only for resnets as they have element wise operations or MobileNets.`)\n",
        "* Threshold for pruning.\n",
        "* A key to save and load the model\n",
        "* Output directory to store the model\n",
        "\n",
        "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. `0.5` in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc4bFeCfjmBG"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/experiment_dir_pruned/300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYIHXWuvjmBG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!tao ssd prune --gpu_index=$GPU_INDEX \\\n",
        "               -m $EXPERIMENT_DIR/experiment_dir_unpruned/300/weights/ssd_resnet10_epoch_$EPOCH.tlt \\\n",
        "               -o $EXPERIMENT_DIR/experiment_dir_pruned/300/ssd_resnet10_pruned.tlt \\\n",
        "               -eq intersection \\\n",
        "               -pth 0.1 \\\n",
        "               -k $KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTujmW7LjmBG"
      },
      "outputs": [],
      "source": [
        "!ls -rlt $EXPERIMENT_DIR/experiment_dir_pruned/300/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4nEXJG0jmBH"
      },
      "source": [
        "## 8. Retrain pruned models <a class=\"anchor\" id=\"head-8\"></a>\n",
        "Model needs to be re-trained to bring back accuracy after pruning\n",
        "Specify re-training specification in the txt retrain file \"ssd_retrain_resnet18_kitti_300.txt\". It is almost the same as the train file with some changes, for example:\n",
        "- Learning rate\n",
        "- Regularized\n",
        "\n",
        "```\n",
        "  learning_rate {\n",
        "    soft_start_annealing_schedule {\n",
        "      min_learning_rate: 5e-5\n",
        "      max_learning_rate: 2e-2\n",
        "      soft_start: 0.15\n",
        "      annealing: 0.8\n",
        "      }\n",
        "  }\n",
        "  regularizer {\n",
        "    type: NO_REG\n",
        "    weight: 3e-9\n",
        "  }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1ErduKSjmBH"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/experiment_dir_retrain/300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGrsXx9TjmBH"
      },
      "outputs": [],
      "source": [
        "# Retraining using the pruned model as pretrained weights\n",
        "!tao ssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n",
        "               -e $SPECS_DIR/300/ssd_retrain_resnet10_kitti.txt \\\n",
        "               -r $EXPERIMENT_DIR/experiment_dir_retrain/300/ \\\n",
        "               -m $EXPERIMENT_DIR/experiment_dir_pruned/300/ssd_resnet10_pruned.tlt \\\n",
        "               -k $KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c98BrCSjmBI"
      },
      "outputs": [],
      "source": [
        "# Listing the newly retrained model.\n",
        "!ls -rlt $EXPERIMENT_DIR/experiment_dir_retrain/300/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaDE0B3XjmBI"
      },
      "outputs": [],
      "source": [
        "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
        "!cat $EXPERIMENT_DIR/experiment_dir_retrain/300/ssd_training_log_resnet10.csv\n",
        "%env EPOCH=010"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkBcw7LjmBI"
      },
      "source": [
        "## 9. Evaluate retrained model <a class=\"anchor\" id=\"head-9\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jImKa-GgjmBI"
      },
      "outputs": [],
      "source": [
        "!tao ssd evaluate --gpu_index=$GPU_INDEX \\\n",
        "                  -e $SPECS_DIR/300/test_set_300.txt \\\n",
        "                  -m $EXPERIMENT_DIR/experiment_dir_retrain/300/weights/ssd_resnet10_epoch_$EPOCH.tlt \\\n",
        "                  -k $KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_JKMIsUjmBI"
      },
      "source": [
        "## 10. Visualize inferences <a class=\"anchor\" id=\"head-10\"></a>\n",
        "In this section, we run the `infer` tool to generate inferences on the trained models and visualize the results. It is important to mention that the \"Non Maximum Suppression\" part is not perform with the model, as a result, the inference will show many bounding boxes for each detected object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wONm4RiQr0L"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/ssd_infer_images\n",
        "!mkdir -p $EXPERIMENT_DIR/ssd_infer_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFQmEPWHjmBI"
      },
      "outputs": [],
      "source": [
        "# Running inference for detection on n images\n",
        "!tao ssd inference --gpu_index=$GPU_INDEX -i $DATA_DIR/test/images \\\n",
        "                   -o $EXPERIMENT_DIR/ssd_infer_images \\\n",
        "                   -e $SPECS_DIR/300/ssd_retrain_resnet10_kitti.txt \\\n",
        "                   -m $EXPERIMENT_DIR/experiment_dir_retrain/300/weights/ssd_resnet10_epoch_$EPOCH.tlt \\\n",
        "                   -l $EXPERIMENT_DIR/ssd_infer_labels \\\n",
        "                   -k $KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zYok3phjmBI"
      },
      "source": [
        "The `tao` inference tool produces two outputs.\n",
        "1. Overlain images in `$EXPERIMENT_DIR/ssd_infer_images`\n",
        "2. Frame by frame bbox labels in kitti format located in `$EXPERIMENT_DIR/ssd_infer_labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X1Rava8jmBI"
      },
      "outputs": [],
      "source": [
        "# Simple grid visualizer\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from math import ceil\n",
        "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
        "\n",
        "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
        "    output_path = os.path.join(os.environ['EXPERIMENT_DIR'], image_dir)\n",
        "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
        "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
        "    f.tight_layout()\n",
        "    a = [os.path.join(output_path, image) for image in os.listdir(output_path)\n",
        "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
        "    for idx, img_path in enumerate(a[:num_images]):\n",
        "        col_id = idx % num_cols\n",
        "        row_id = idx // num_cols\n",
        "        img = plt.imread(img_path)\n",
        "        axarr[row_id, col_id].imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H48lVM1mjmBJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the sample images.\n",
        "OUTPUT_PATH = 'ssd_infer_images' # relative path from $EXPERIMENT_DIR.\n",
        "COLS = 3 # number of columns in the visualizer grid.\n",
        "IMAGES = 9 # number of images to visualize.\n",
        "\n",
        "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTUQg0GkYnkF"
      },
      "source": [
        "# Deployment\n",
        "In this part we will create the \".etlt\" file that is going to be our input to deepstream where the \".engine\" file will be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbCIDvzaAl91"
      },
      "outputs": [],
      "source": [
        "%env KEY=nvidia_tlt\n",
        "#FIXME1\n",
        "%env NUM_GPUS=1\n",
        "#FIXME2\n",
        "%env GPU_INDEX=0\n",
        "#FIXME3\n",
        "%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/perceptionAI/TechGo/nvidia-tao\n",
        "#FIXME4\n",
        "%env EXPERIMENT_DIR=/content/drive/MyDrive/perceptionAI/TechGo/TAO/results/ssd\n",
        "%env DATA_DIR=/content/drive/MyDrive/perceptionAI/TechGo/data/TechKITTI/\n",
        "SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/ssd/specs\"\n",
        "%env SPECS_DIR={SPECS_DIR}\n",
        "\n",
        "%env EPOCH=010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4GaWiX7sZsZi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $EXPERIMENT_DIR/experiment_dir_etlt/300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3S_NKBBAvkI"
      },
      "source": [
        "Importante considerations\n",
        "- Set \"data_type\" to fp16 or fp32\n",
        "- \"gen_ds_config\" will output a \"nvinfer_config.txt\" file that shows important configurations to take into account in the configuration file of the model in deepstream \"tech_ssd_config.txt\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bKrnv76bYrm_"
      },
      "outputs": [],
      "source": [
        "!tao ssd export -m $EXPERIMENT_DIR/experiment_dir_retrain/300/weights/ssd_resnet10_epoch_010.tlt \\\n",
        "                         -o $EXPERIMENT_DIR/experiment_dir_etlt/300/ssd_resnet10_epoch_10_fp32.etlt \\\n",
        "                         -e $SPECS_DIR/300/ssd_retrain_resnet10_kitti.txt \\\n",
        "                         -k $KEY \\\n",
        "                         --data_type fp32 \\\n",
        "                         --gen_ds_config \\\n",
        "                         --target_opset 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZKpalN3FjEf"
      },
      "source": [
        "# MLFLOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rof_y7qvFoBX"
      },
      "source": [
        "This section is for saving all the parameters and metrics of the trained model with mlflow. Remember to first import manually your \"mlflow.db\" database. If it is your first trained model, and you do not have a database, you can run in your local machine in cli \"mlflow ui --backend-store-uri sqlite:///mlflow.db\" and the database will be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OZ20HRkFlaU"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5dfDEjFsRC"
      },
      "source": [
        "We need to authenticate in order to save the artifacts into s3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aitg4vwgFqS8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/MyDrive/config/awscli.ini\n",
        "path = \"/content/drive/MyDrive/config/awscli.ini\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_g4xwe-Fv9i"
      },
      "source": [
        "In this case we will save the training configuration files as artifacts and some additional parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P5keSNRGFqWO"
      },
      "outputs": [],
      "source": [
        "# Params\n",
        "pre_trained_weights = 'resnet10'\n",
        "pruning_threshold = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u46BYZx6Fx4m"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "expr_name = \"object_detection\"\n",
        "\n",
        "s3_bucket = f\"s3://elvis-s3-mlflow/mlruns/{expr_name}\"\n",
        "\n",
        "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
        "experiment = mlflow.get_experiment_by_name(expr_name)\n",
        "if not experiment:\n",
        "    mlflow.create_experiment(expr_name, s3_bucket)\n",
        "\n",
        "mlflow.set_experiment(expr_name)\n",
        "\n",
        "mlflow.start_run('64b6f7b983864931a88b766a90072562')\n",
        "# mlflow.set_tag(\"mlflow.runName\", 'ssdresnet10_fp16')\n",
        "\n",
        "# Params\n",
        "mlflow.log_param(\"pre_trained_weights\", pre_trained_weights)\n",
        "mlflow.log_param(\"pruning_threshold\", pruning_threshold)\n",
        "\n",
        "# Train params\n",
        "mlflow.log_artifacts('/content/drive/MyDrive/perceptionAI/TechGo/nvidia-tao/tensorflow/ssd/specs/300', artifact_path=\"train_params\")\n",
        "\n",
        "# Evaluate\n",
        "mlflow.end_run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
